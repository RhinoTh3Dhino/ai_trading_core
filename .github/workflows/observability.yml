name: observability

on:
  push:
    paths:
      - "bot/live_connector/**"
      - "ops/**"
      - "tests/**"
      - ".github/workflows/observability.yml"
  pull_request:
    paths:
      - "bot/live_connector/**"
      - "ops/**"
      - "tests/**"
      - ".github/workflows/observability.yml"
  schedule:
    - cron: "0 5 * * *"   # daglig check
  workflow_dispatch:

concurrency:
  group: observability-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  PYTHONUNBUFFERED: "1"
  MPLBACKEND: Agg

jobs:
  unit-smoke:
    name: Smoke /metrics + promtool + tests
    runs-on: ubuntu-latest
    timeout-minutes: 20

    outputs:
      has_dockerfile: ${{ steps.detect_dockerfile.outputs.present }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Detect Dockerfile
        id: detect_dockerfile
        shell: bash
        run: |
          if [ -f Dockerfile ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Setup Python 3.11 (cache=pip)
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies (incl. CPU PyTorch like CI)
        run: |
          set -euxo pipefail
          python -m pip install -U pip wheel setuptools

          # Installer projektkrav hvis findes; ellers minimumspakke-sæt
          if [ -f requirements.txt ]; then
            # numeric først for hurtigere hjul
            pip install --only-binary=:all: 'numpy==1.26.4' 'pyarrow==11.0.0' || true
            pip install -r requirements.txt
          else
            pip install fastapi uvicorn prometheus-client httpx pytest
          fi

          # CPU-PyTorch (samme pins som i CI) – må gerne fejle
          pip install --extra-index-url https://download.pytorch.org/whl/cpu \
            'torch==2.2.2' 'torchvision==0.17.2' 'torchaudio==2.2.2' || true

          # Versionsinfo
          python - <<'PY'
          import importlib
          for name in ("torch","torchvision","torchaudio","fastapi","uvicorn","prometheus_client","numpy","pyarrow","pytest"):
              try:
                  m = importlib.import_module(name)
                  print(f"{name}: {getattr(m,'__version__','?')}")
              except Exception as e:
                  print(f"{name}: <missing> ({e})")
          PY

      - name: Launch app (uvicorn) in background
        run: |
          set -euxo pipefail
          nohup uvicorn bot.live_connector.runner:app \
            --host 0.0.0.0 --port 8000 --workers 1 >/tmp/app.log 2>&1 &
          for i in {1..60}; do
            if curl -fsS http://localhost:8000/healthz >/dev/null; then
              echo "healthz OK"; break
            fi
            sleep 1
          done
          curl -fsS http://localhost:8000/metrics | head -n 5

      - name: Smoke /metrics contains core metrics
        run: |
          set -euxo pipefail
          curl -fsS http://localhost:8000/metrics | tee /tmp/metrics.txt
          grep -q "feed_transport_latency_ms_bucket" /tmp/metrics.txt
          grep -q "feed_bar_close_lag_ms"          /tmp/metrics.txt
          grep -q "feed_bars_total"                /tmp/metrics.txt
          grep -q "feed_reconnects_total"          /tmp/metrics.txt
          grep -q "feed_queue_depth"               /tmp/metrics.txt
          grep -q "feature_compute_ms_bucket"      /tmp/metrics.txt

      # ---------- promtool forberedelse: sørg for alle filer findes ----------
      - name: Ensure Prometheus rule files exist (create minimal if missing)
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p ops/prometheus

          if [ ! -f ops/prometheus/alerts.yml ]; then
            printf '%s\n' \
              'groups:' \
              '  - name: alerts.empty' \
              '    rules: []' \
              > ops/prometheus/alerts.yml
          fi

          if [ ! -f ops/prometheus/recording_rules.yml ]; then
            printf '%s\n' \
              'groups:' \
              '  - name: recordings.empty' \
              '    rules: []' \
              > ops/prometheus/recording_rules.yml
          fi

          test -f ops/prometheus/prometheus.yml

      - name: promtool check config (prometheus.yml)
        run: |
          set -euxo pipefail
          docker run --rm \
            -v "$PWD/ops/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro" \
            -v "$PWD/ops/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro" \
            -v "$PWD/ops/prometheus/recording_rules.yml:/etc/prometheus/recording_rules.yml:ro" \
            --entrypoint=promtool \
            prom/prometheus:v2.53.0 \
            check config /etc/prometheus/prometheus.yml

      - name: promtool check rules (alerts.yml)
        run: |
          set -euxo pipefail
          docker run --rm \
            -v "$PWD/ops/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro" \
            --entrypoint=promtool \
            prom/prometheus:v2.53.0 \
            check rules /etc/prometheus/alerts.yml

      - name: promtool check rules (recording_rules.yml)
        run: |
          set -euxo pipefail
          docker run --rm \
            -v "$PWD/ops/prometheus/recording_rules.yml:/etc/prometheus/recording_rules.yml:ro" \
            --entrypoint=promtool \
            prom/prometheus:v2.53.0 \
            check rules /etc/prometheus/recording_rules.yml

      # Hold observability-jobbet hurtigt: kør kun metrics-testen her
      - name: Run tests (metrics only)
        run: pytest -q tests/test_metrics_exposition.py

      - name: Upload metrics and logs (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: observability-smoke-artifacts
          path: |
            /tmp/metrics.txt
            /tmp/app.log

  compose-integration:
    name: Compose integration (target=UP)
    needs: unit-smoke
    runs-on: ubuntu-latest
    timeout-minutes: 25
    if: ${{ needs.unit-smoke.outputs.has_dockerfile == 'true' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install jq (for API checks)
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Compose up (live_connector + prometheus only)
        working-directory: ops/compose
        run: |
          set -euxo pipefail
          # Start kun default-profil (alertmanager/grafana ligger i profiler)
          docker compose -f docker-compose.yml up -d live_connector prometheus

          # Vent på Prometheus readiness
          for i in {1..90}; do
            if curl -fsS http://localhost:9090/-/ready >/dev/null; then
              echo "Prometheus ready"; break
            fi
            sleep 2
          done

          # Vent på app /metrics
          for i in {1..60}; do
            if curl -fsS http://localhost:8000/metrics >/dev/null; then
              echo "metrics OK"; break
            fi
            sleep 1
          done

      - name: Verify Prometheus target is UP
        run: |
          set -euxo pipefail
          curl -fsS "http://localhost:9090/api/v1/targets" | tee /tmp/targets.json
          jq -e '.data.activeTargets | map(select(.health=="up")) | length > 0' /tmp/targets.json >/dev/null

      - name: Dump Prometheus target summaries
        if: always()
        run: |
          jq '.data.activeTargets[] | {job:.labels.job, health, scrapeUrl, lastError}' /tmp/targets.json || true

      - name: Compose logs (on failure)
        if: failure()
        working-directory: ops/compose
        run: |
          docker compose -f docker-compose.yml ps
          docker compose -f docker-compose.yml logs --no-color --tail=200 live_connector || true
          docker compose -f docker-compose.yml logs --no-color --tail=200 prometheus || true

      - name: Compose down
        if: always()
        working-directory: ops/compose
        run: docker compose -f docker-compose.yml down -v

      - name: Upload compose artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: observability-compose-artifacts
          path: |
            /tmp/targets.json
